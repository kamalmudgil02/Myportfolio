<!DOCTYPE html>
<html lang="en" data-theme="dark">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog | Kamal Sharma</title>
    <meta name="author" content="Kamal Sharma">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Space+Grotesk:wght@500;600;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="styles.css">
    <style>
        /* â”€â”€ Blog reader page styles â”€â”€ */
        .blog-page {
            padding: 6rem 0 4rem;
            min-height: 100vh;
        }

        .blog-nav-bar {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 2.5rem;
            flex-wrap: wrap;
            gap: 1rem;
        }

        .back-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.55rem 1.25rem;
            background: var(--bg-secondary);
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-md);
            color: var(--text-primary);
            font-weight: 600;
            font-size: 0.9rem;
            text-decoration: none;
            transition: all var(--transition-normal);
        }

        .back-btn:hover {
            background: var(--primary-blue);
            color: white;
            border-color: var(--primary-blue);
        }

        .blog-article {
            background: var(--bg-secondary);
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-xl);
            padding: 3rem;
            max-width: 820px;
            margin: 0 auto;
        }

        .post-meta-row {
            display: flex;
            align-items: center;
            gap: 1rem;
            flex-wrap: wrap;
            margin-bottom: 1.5rem;
        }

        .post-tag {
            background: rgba(59, 130, 246, 0.15);
            color: var(--primary-blue);
            padding: 0.3rem 0.9rem;
            border-radius: 2rem;
            font-size: 0.8rem;
            font-weight: 600;
        }

        .post-meta-item {
            display: flex;
            align-items: center;
            gap: 0.35rem;
            font-size: 0.82rem;
            color: var(--text-tertiary);
        }

        .post-icon-hero {
            width: 72px;
            height: 72px;
            background: var(--accent-gradient);
            border-radius: var(--radius-lg);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 2rem;
            color: white;
            box-shadow: var(--shadow-lg);
            margin-bottom: 1.5rem;
        }

        .post-title {
            font-size: 2rem;
            font-weight: 700;
            line-height: 1.3;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }

        .post-body {
            font-size: 1rem;
            line-height: 1.85;
            color: var(--text-secondary);
        }

        .post-body h2 {
            font-size: 1.35rem;
            color: var(--text-primary);
            margin: 2rem 0 0.75rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid var(--glass-border);
        }

        .post-body h3 {
            font-size: 1.1rem;
            color: var(--primary-blue);
            margin: 1.5rem 0 0.5rem;
        }

        .post-body p {
            margin-bottom: 1.1rem;
        }

        .post-body ul,
        .post-body ol {
            padding-left: 1.5rem;
            margin-bottom: 1.1rem;
        }

        .post-body li {
            margin-bottom: 0.5rem;
        }

        .post-body strong {
            color: var(--text-primary);
        }

        .post-body code {
            background: var(--bg-tertiary);
            color: var(--primary-blue);
            padding: 0.15rem 0.45rem;
            border-radius: 0.3rem;
            font-size: 0.88rem;
            font-family: 'Courier New', monospace;
        }

        .post-body .tip-box {
            background: rgba(16, 185, 129, 0.08);
            border-left: 4px solid #10B981;
            border-radius: 0 0.5rem 0.5rem 0;
            padding: 1rem 1.25rem;
            margin: 1.5rem 0;
            font-size: 0.9rem;
        }

        .post-body .tip-box strong {
            color: #10B981;
        }

        .post-divider {
            border: none;
            border-top: 1px solid var(--glass-border);
            margin: 2rem 0;
        }

        .author-box {
            display: flex;
            align-items: center;
            gap: 1rem;
            background: var(--bg-primary);
            border-radius: var(--radius-md);
            padding: 1.25rem;
            margin-top: 2rem;
        }

        .author-avatar {
            width: 52px;
            height: 52px;
            background: var(--accent-gradient);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.4rem;
            color: white;
            flex-shrink: 0;
        }

        .author-name {
            font-weight: 700;
            font-size: 0.95rem;
        }

        .author-bio {
            font-size: 0.82rem;
            color: var(--text-secondary);
            margin-top: 0.2rem;
        }

        .not-found {
            text-align: center;
            padding: 4rem 1rem;
        }

        .not-found i {
            font-size: 3rem;
            color: var(--text-tertiary);
            margin-bottom: 1rem;
        }

        /* Light mode */
        [data-theme="light"] .blog-article {
            background: #FFFFFF;
            box-shadow: var(--shadow-md);
        }

        [data-theme="light"] .back-btn {
            background: #F8FAFC;
        }

        [data-theme="light"] .author-box {
            background: #F1F5F9;
        }

        @media (max-width: 640px) {
            .blog-article {
                padding: 1.75rem 1.25rem;
            }

            .post-title {
                font-size: 1.5rem;
            }
        }
    </style>
</head>

<body>
    <!-- Navbar (re-used from main site) -->
    <nav class="navbar" id="navbar">
        <div class="container nav-container">
            <a href="index.html" class="logo">
                <span class="logo-text">Kamal<span class="highlight">.</span></span>
            </a>
            <div class="nav-actions">
                <a href="index.html#blog" class="back-btn">
                    <i class="fas fa-arrow-left"></i> All Posts
                </a>
                <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </div>
    </nav>

    <main class="blog-page">
        <div class="container">
            <div id="postContent"><!-- filled by JS --></div>
        </div>
    </main>

    <script>
        // â”€â”€ Blog post data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const posts = {
            1: {
                tag: 'Artificial Intelligence',
                date: 'Feb 2025',
                readTime: '5 min read',
                icon: 'fas fa-brain',
                title: 'Getting Started with AI: A Beginner\'s Roadmap',
                body: `
                <p>Artificial Intelligence can feel overwhelming at first â€” countless frameworks, research papers, and tutorials all pulling you in different directions. This post cuts through the noise and gives you a <strong>clear, linear path</strong> to go from zero to building your first neural network.</p>

                <h2>Phase 1: Math Foundations</h2>
                <p>You don't need to be a mathematician, but you do need a working understanding of:</p>
                <ul>
                    <li><strong>Linear Algebra</strong> â€” vectors, matrices, dot products (3Blue1Brown on YouTube is gold)</li>
                    <li><strong>Calculus</strong> â€” derivatives, chain rule (used in backpropagation)</li>
                    <li><strong>Probability & Statistics</strong> â€” distributions, Bayes' theorem, expectation</li>
                </ul>
                <div class="tip-box"><strong>ðŸ’¡ Tip:</strong> Don't block yourself on math. Learn just enough to understand a concept, then move forward. You'll revisit and deepen your understanding naturally.</div>

                <h2>Phase 2: Python Programming</h2>
                <p>Python is the language of AI. You should be comfortable with:</p>
                <ul>
                    <li>Data structures: lists, dicts, sets, tuples</li>
                    <li>NumPy for array operations</li>
                    <li>Pandas for data manipulation</li>
                    <li>Matplotlib / Seaborn for visualization</li>
                </ul>

                <h2>Phase 3: Machine Learning Core Concepts</h2>
                <p>Use <strong>Scikit-learn</strong> to implement and understand:</p>
                <ul>
                    <li>Linear & Logistic Regression</li>
                    <li>Decision Trees and Random Forests</li>
                    <li>K-Means Clustering</li>
                    <li>Train/Val/Test splits, overfitting, regularization</li>
                </ul>

                <h2>Phase 4: Deep Learning</h2>
                <p>Once ML fundamentals click, move to <strong>TensorFlow/Keras</strong> or <strong>PyTorch</strong>:</p>
                <ul>
                    <li>Build a simple ANN from scratch</li>
                    <li>Understand backpropagation intuitively</li>
                    <li>Train CNNs on image datasets (MNIST, CIFAR-10)</li>
                    <li>Experiment with transfer learning using pre-trained models</li>
                </ul>

                <h2>Phase 5: Build Projects</h2>
                <p>Nothing solidifies learning like real projects. Start with:</p>
                <ul>
                    <li>Spam email classifier</li>
                    <li>Digit recognizer (MNIST)</li>
                    <li>Sentiment analysis on movie reviews</li>
                </ul>
                <div class="tip-box"><strong>ðŸŽ¯ Goal:</strong> Push everything to GitHub. A portfolio of 3â€“5 working projects is worth more than 10 certificates on a resume.</div>

                <h2>Recommended Resources</h2>
                <ul>
                    <li><strong>Fast.ai</strong> â€” practical deep learning for coders</li>
                    <li><strong>Coursera â€“ Andrew Ng's ML Specialization</strong></li>
                    <li><strong>Kaggle</strong> â€” practice with real datasets and competitions</li>
                    <li><strong>Papers With Code</strong> â€” read and replicate research</li>
                </ul>
            `
            },
            2: {
                tag: 'Deep Learning',
                date: 'Jan 2025',
                readTime: '7 min read',
                icon: 'fas fa-network-wired',
                title: 'Understanding CNNs: How Machines See the World',
                body: `
                <p>Convolutional Neural Networks (CNNs) are the backbone of modern computer vision. From face recognition on your phone to medical imaging AI, CNNs power it all. But how do they actually work? Let's break it down visually and intuitively.</p>

                <h2>Why Not a Regular Neural Network?</h2>
                <p>A standard fully-connected (dense) neural network would treat an image as a flat vector of pixels. A 224Ã—224 color image has <strong>150,528 values</strong>. Connecting all of these to even one hidden layer of 1000 neurons means 150 million parameters â€” before the first layer. This is:</p>
                <ul>
                    <li>Computationally expensive</li>
                    <li>Prone to overfitting</li>
                    <li>Ignores spatial relationships between pixels</li>
                </ul>
                <p>CNNs solve all three problems.</p>

                <h2>The Convolution Operation</h2>
                <p>A <strong>filter (kernel)</strong> is a small matrix (e.g., 3Ã—3) that slides across the image, computing a dot product at each position. This produces a <strong>feature map</strong> that highlights specific patterns â€” edges, corners, textures.</p>
                <div class="tip-box"><strong>ðŸ’¡ Insight:</strong> Early layers detect low-level features (edges, gradients). Deeper layers combine these to detect high-level features (eyes, wheels, faces).</div>

                <h2>Key CNN Layers</h2>
                <h3>1. Convolutional Layer</h3>
                <p>Applies multiple learnable filters to the input. Each filter specializes in detecting a different pattern. Output = stack of feature maps.</p>

                <h3>2. Activation (ReLU)</h3>
                <p><code>f(x) = max(0, x)</code> â€” Introduces non-linearity. Without it, all layers collapse into a single linear operation.</p>

                <h3>3. Pooling Layer</h3>
                <p>Reduces spatial dimensions (e.g., 28Ã—28 â†’ 14Ã—14) using Max Pooling â€” keeps the strongest activation in each region. This makes the model <strong>translation-invariant</strong>: a cat is recognized whether it's in the center or corner of the image.</p>

                <h3>4. Fully Connected Layer</h3>
                <p>After several Conv+Pool blocks, the feature maps are flattened and fed into dense layers for final classification.</p>

                <h2>Famous CNN Architectures</h2>
                <ul>
                    <li><strong>LeNet-5 (1998)</strong> â€” the original, designed for digit recognition</li>
                    <li><strong>AlexNet (2012)</strong> â€” won ImageNet, sparked the deep learning revolution</li>
                    <li><strong>VGG-16 (2014)</strong> â€” simple, deep, easy to understand</li>
                    <li><strong>ResNet (2015)</strong> â€” introduced skip connections to train very deep networks</li>
                    <li><strong>EfficientNet (2019)</strong> â€” state of the art efficiency-accuracy trade-off</li>
                </ul>

                <h2>Hands-on: Build a Simple CNN in Keras</h2>
                <p>The best way to understand CNNs is to build one. Start with the MNIST or CIFAR-10 dataset in TensorFlow/Keras, add Conv2D â†’ MaxPooling â†’ Dense layers, and watch accuracy improve. Visualizing feature maps using <code>tf.keras.Model</code> intermediate outputs is extremely educational.</p>
                <div class="tip-box"><strong>ðŸŽ¯ Try this:</strong> Use <strong>Grad-CAM</strong> to visualize which parts of an image the CNN is "looking at" when making a prediction. It builds incredible intuition.</div>
            `
            },
            3: {
                tag: 'Embedded Systems',
                date: 'Dec 2024',
                readTime: '6 min read',
                icon: 'fas fa-microchip',
                title: 'Arduino to MATLAB: Bridging Hardware and Data',
                body: `
                <p>One of the most rewarding projects I worked on during my ECE studies was connecting an Arduino sensor board to MATLAB for real-time data acquisition and analysis. This bridge between hardware and software is incredibly powerful â€” and easier than you might think.</p>

                <h2>Why This Combination?</h2>
                <ul>
                    <li><strong>Arduino</strong> â€” inexpensive, beginner-friendly microcontroller with huge community support</li>
                    <li><strong>MATLAB</strong> â€” industry-standard for signal processing, data analysis, and visualization</li>
                    <li>Together they let you <strong>capture real-world signals</strong> and <strong>analyze them instantly</strong></li>
                </ul>

                <h2>Hardware Setup</h2>
                <p>For this project, I used:</p>
                <ul>
                    <li>Arduino Uno</li>
                    <li>DHT11 temperature & humidity sensor</li>
                    <li>USB cable for serial communication</li>
                </ul>
                <p>The Arduino reads sensor data and sends it over the <strong>Serial port</strong> at a set baud rate (e.g., 9600). MATLAB listens on the same port and reads the incoming data stream.</p>

                <h2>Arduino Sketch (Firmware)</h2>
                <p>The Arduino code initializes the sensor, reads values every 500ms, and prints them in a CSV format: <code>temperature,humidity\n</code>. This structured format makes it easy to parse on the MATLAB side.</p>

                <h2>MATLAB Side: Reading Serial Data</h2>
                <p>MATLAB's <code>serialport()</code> function (or the older <code>serial()</code>) opens a connection to the Arduino's COM port. You then read lines in a loop, parse the CSV values with <code>strsplit()</code>, and store them in arrays for real-time plotting with <code>drawnow</code>.</p>
                <div class="tip-box"><strong>ðŸ’¡ Tip:</strong> Use MATLAB's <strong>Support Package for Arduino Hardware</strong> for even tighter integration â€” it lets you control Arduino pins directly from MATLAB without writing any Arduino C code.</div>

                <h2>Real-time Visualization</h2>
                <p>The key to real-time plotting in MATLAB is the <code>drawnow</code> command. After each data point, update your plot data with <code>set(lineHandle, 'YData', dataArray)</code> and call <code>drawnow</code> to refresh â€” much more efficient than calling <code>plot()</code> in a loop.</p>

                <h2>Applications</h2>
                <ul>
                    <li>Environmental monitoring (temp, humidity, air quality)</li>
                    <li>Vibration and noise analysis for predictive maintenance</li>
                    <li>ECG/EEG signal acquisition</li>
                    <li>Motor speed and torque measurement</li>
                    <li>Real-time FFT of analog signals</li>
                </ul>

                <h2>Taking It Further</h2>
                <p>Once you're comfortable with basic serial communication, explore MATLAB's <strong>Signal Processing Toolbox</strong> to apply filters, FFT, and spectral analysis to your sensor data. This combination of hardware sensing and software analysis is exactly what's needed in fields like <strong>predictive maintenance</strong> and <strong>biomedical instrumentation</strong>.</p>
                <div class="tip-box"><strong>ðŸŽ¯ Project idea:</strong> Build a vibration monitor â€” attach an accelerometer to machinery, stream to MATLAB, apply FFT, and detect anomalies in the frequency spectrum. Great for a portfolio project!</div>
            `
            },
            4: {
                tag: 'Python',
                date: 'Nov 2024',
                readTime: '4 min read',
                icon: 'fab fa-python',
                title: 'Python Libraries Every AI Student Should Know',
                body: `
                <p>Python's strength in AI/ML comes from its incredible ecosystem. But with hundreds of libraries available, which ones actually matter? Here's my curated, practical list â€” the ones I use in nearly every project.</p>

                <h2>Core Data Science Stack</h2>
                <h3>1. NumPy</h3>
                <p>The foundation of almost everything. NumPy provides fast multi-dimensional arrays and mathematical operations. If you're doing any numerical computation, you're using NumPy â€” often without realizing it.</p>
                <ul>
                    <li>Array slicing, broadcasting, vectorized operations</li>
                    <li>Linear algebra (<code>np.linalg</code>), FFT (<code>np.fft</code>)</li>
                    <li>Essential for understanding how tensors work in frameworks like TensorFlow</li>
                </ul>

                <h3>2. Pandas</h3>
                <p>Your go-to for data wrangling. Think of it as Excel, but programmable and infinitely more powerful.</p>
                <ul>
                    <li>DataFrames for tabular data</li>
                    <li>Handling missing values, groupby, merge, pivot</li>
                    <li>Reading CSV, Excel, JSON, SQL with one line of code</li>
                </ul>

                <h3>3. Matplotlib & Seaborn</h3>
                <p>Visualization is critical â€” in AI you need to <em>see</em> what your data looks like before modeling. Matplotlib is low-level and flexible; Seaborn is higher-level and makes beautiful statistical plots with minimal code.</p>

                <h2>Machine Learning</h2>
                <h3>4. Scikit-learn</h3>
                <p>The gold standard for classical ML. Every algorithm follows the same <code>.fit() / .predict()</code> API, making it incredibly intuitive.</p>
                <ul>
                    <li>Classification, regression, clustering, dimensionality reduction</li>
                    <li>Cross-validation, pipelines, GridSearchCV</li>
                    <li>Preprocessing: StandardScaler, LabelEncoder, train_test_split</li>
                </ul>
                <div class="tip-box"><strong>ðŸ’¡ Rule of thumb:</strong> Start with Scikit-learn for any new ML problem. Only move to deep learning if simpler models underperform.</div>

                <h2>Deep Learning</h2>
                <h3>5. TensorFlow / Keras</h3>
                <p>Google's powerhouse. Keras (now tightly integrated with TF2) makes building neural networks feel like stacking LEGO blocks. Great for beginners and production alike.</p>

                <h3>6. PyTorch</h3>
                <p>The research community's favourite. Dynamic computation graph, pythonic feel, and excellent debugging. If you want to understand what's happening inside a model, PyTorch is superior for learning.</p>

                <h2>Computer Vision & Signal Processing</h2>
                <h3>7. OpenCV</h3>
                <p>Essential for anything image or video related â€” reading frames, color space conversion, edge detection, object detection, camera calibration. Used heavily in embedded + AI projects.</p>

                <h2>Utilities You'll Use Daily</h2>
                <ul>
                    <li><strong>os / pathlib</strong> â€” file system navigation</li>
                    <li><strong>tqdm</strong> â€” progress bars for loops</li>
                    <li><strong>Pillow (PIL)</strong> â€” image loading and transformations</li>
                    <li><strong>SciPy</strong> â€” scientific computing, signal processing, optimization</li>
                    <li><strong>Joblib</strong> â€” parallelism and model serialization</li>
                </ul>
                <div class="tip-box"><strong>ðŸŽ¯ Learning path:</strong> NumPy â†’ Pandas â†’ Matplotlib â†’ Scikit-learn â†’ TensorFlow or PyTorch. Master each before moving to the next.</div>
            `
            },
            5: {
                tag: 'Career',
                date: 'Oct 2024',
                readTime: '8 min read',
                icon: 'fas fa-graduation-cap',
                title: 'ECE to AI: Navigating the Transition',
                body: `
                <p>When I told people I was an ECE student interested in pursuing AI for my Master's, the reactions were mixed. "Isn't AI for CS students?" and "Do you even know to code?" were common. This post is for every ECE student wondering if the leap into AI is possible â€” it absolutely is, and your background is actually a <strong>huge advantage</strong>.</p>

                <h2>What ECE Gives You (That CS Doesn't)</h2>
                <p>ECE students are trained to think in signals, systems, and hardware. This maps beautifully to AI in ways many people miss:</p>
                <ul>
                    <li><strong>Signal processing â†’ Feature engineering & time-series AI</strong></li>
                    <li><strong>Control systems â†’ Reinforcement learning concepts</strong></li>
                    <li><strong>Embedded systems â†’ Edge AI (TensorFlow Lite, ONNX on microcontrollers)</strong></li>
                    <li><strong>Circuit analysis â†’ Understanding hardware accelerators (TPUs, GPUs)</strong></li>
                    <li><strong>Mathematics foundation â†’ Linear algebra, calculus for DL are already covered</strong></li>
                </ul>
                <div class="tip-box"><strong>ðŸ’¡ Insight:</strong> AI is increasingly deployed at the <em>edge</em> â€” on tiny sensors, microcontrollers, and FPGAs. ECE students who understand both the AI side and the hardware side are <strong>extremely rare and valuable</strong>.</div>

                <h2>What You Need to Build</h2>
                <h3>Programming Skills</h3>
                <p>The biggest gap most ECE students face is programming confidence. C/C++ is great, but you need strong Python. Commit to 2â€“3 months of consistent Python practice, then jump straight into NumPy and Scikit-learn.</p>

                <h3>ML/DL Fundamentals</h3>
                <p>Take Andrew Ng's Machine Learning Specialization on Coursera (free to audit). Follow with his Deep Learning Specialization. These are specifically designed to be accessible without a CS background.</p>

                <h3>Projects That Combine ECE + AI</h3>
                <p>This is your secret weapon. Build projects that showcase both worlds:</p>
                <ul>
                    <li>AI-based predictive maintenance using vibration sensor data</li>
                    <li>Real-time object detection on Raspberry Pi</li>
                    <li>Fault classification in power systems using CNNs</li>
                    <li>Smart home automation with voice commands (speech AI + embedded)</li>
                </ul>

                <h2>MS Admissions Strategy</h2>
                <p>Top programs like CMU, Stanford, and Georgia Tech value diverse backgrounds. As an ECE student applying to AI/ML programs:</p>
                <ul>
                    <li><strong>Highlight interdisciplinary projects</strong> â€” your hardware-AI projects stand out</li>
                    <li><strong>SOP is critical</strong> â€” explain WHY ECE â†’ AI, make it a cohesive narrative</li>
                    <li><strong>Research experience matters</strong> â€” even informal, document it</li>
                    <li><strong>GRE/TOEFL</strong> â€” aim for 320+ GRE for top programs</li>
                    <li><strong>GitHub portfolio</strong> â€” 5 solid projects speak louder than 20 certificates</li>
                </ul>

                <h2>My Personal Journey</h2>
                <p>I started with zero Python knowledge in my 2nd year. I broke down and learned systematically: Python â†’ NumPy â†’ ML basics â†’ TensorFlow. The turning point was my first project combining signal processing (my ECE strength) with a neural network. It clicked â€” I understood concretely what I was building and why it worked. That project became the centerpiece of my portfolio.</p>
                <div class="tip-box"><strong>ðŸŽ¯ Advice:</strong> Don't wait until you "know enough" to start projects. Start messy, learn along the way. Your first 3 projects will be terrible â€” and that's perfect.</div>
            `
            },
            6: {
                tag: 'NLP',
                date: 'Sep 2024',
                readTime: '5 min read',
                icon: 'fas fa-comment-dots',
                title: 'Prompt Engineering: The New Developer Skill',
                body: `
                <p>A year ago, "prompt engineering" sounded like a buzzword. Today, it's a genuine skill that can dramatically change how useful AI tools are in your workflow. Whether you're using ChatGPT, GitHub Copilot, or Gemini, <strong>how you write your prompts determines the quality of the output</strong>.</p>

                <h2>Why Prompts Matter</h2>
                <p>Large Language Models (LLMs) are next-token predictors â€” they complete text based on patterns learned from massive datasets. Feed them an ambiguous input, you get an ambiguous output. Feed them a precise, well-structured input, and the output quality shoots up dramatically.</p>
                <div class="tip-box"><strong>ðŸ’¡ Mental model:</strong> Treat the LLM like a very smart intern on their first day. They need context, clear instructions, and examples of what "good" looks like. Don't assume they'll infer what you mean.</div>

                <h2>Core Prompt Engineering Techniques</h2>

                <h3>1. Zero-Shot Prompting</h3>
                <p>Simply describe the task. Works for straightforward requests: <code>"Summarize the following text in 3 bullet points:"</code>. Effective for well-defined tasks where the model has strong prior knowledge.</p>

                <h3>2. Few-Shot Prompting</h3>
                <p>Provide 2â€“5 examples of inputâ†’output pairs before your actual query. The model picks up the pattern and applies it. This is especially powerful for formatting, tone, or classification tasks.</p>

                <h3>3. Chain-of-Thought (CoT)</h3>
                <p>Add <code>"Let's think step by step"</code> to prompts involving reasoning or math. This forces the model to show its work, dramatically reducing errors on multi-step problems. One of the most impactful single-phrase techniques in prompting.</p>

                <h3>4. Role Prompting</h3>
                <p><code>"You are an expert Python developer with 10 years of experience. Review this code and suggest improvements:"</code> â€” assigning a persona changes the model's response style, depth, and vocabulary significantly.</p>

                <h3>5. Structured Output Prompting</h3>
                <p>Tell the model exactly what format you want: <code>"Respond in JSON with keys: title, summary, tags"</code>. This is essential when programmatically using LLM outputs in applications.</p>

                <h2>Practical Tips from Experience</h2>
                <ul>
                    <li><strong>Be specific over vague</strong> â€” "Write a 200-word professional summary for a resume" > "Write about me"</li>
                    <li><strong>Iterate</strong> â€” treat your first prompt as a draft; refine based on the output</li>
                    <li><strong>Use delimiters</strong> â€” wrap sections with <code>""" """</code> or <code>### ###</code> to clearly separate instructions from content</li>
                    <li><strong>State what to avoid</strong> â€” "Do not include bullet points" is as important as what to include</li>
                    <li><strong>Break complex tasks</strong> into sub-tasks across multiple prompts rather than one mega-prompt</li>
                </ul>

                <h2>Prompt Engineering for Code</h2>
                <p>For coding tasks (Copilot, Code Llama, GPT-4), the most effective pattern is:</p>
                <ol>
                    <li>State the <strong>goal</strong> in one sentence</li>
                    <li>List <strong>constraints</strong> (language, library version, no external APIs)</li>
                    <li>Provide <strong>context</strong> (existing code, data structure)</li>
                    <li>Ask for <strong>explanation</strong> alongside code</li>
                </ol>

                <h2>The Future</h2>
                <p>As AI becomes increasingly integrated into development workflows, prompt engineering is becoming as fundamental as knowing how to use Stack Overflow. The developers who learn to work <em>with</em> AI effectively â€” not just copy-paste its output â€” will have a significant edge.</p>
                <div class="tip-box"><strong>ðŸŽ¯ Practice:</strong> Pick any tool you use daily (ChatGPT, Copilot, Gemini) and spend one week deliberately experimenting with different prompt strategies for the same task. You'll be surprised at the difference.</div>
            `
            }
        };

        // â”€â”€ Render post â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        function renderPost() {
            const params = new URLSearchParams(window.location.search);
            const id = parseInt(params.get('post'));
            const post = posts[id];
            const container = document.getElementById('postContent');

            if (!post) {
                container.innerHTML = `
                <div class="not-found">
                    <i class="fas fa-file-circle-question"></i>
                    <h2>Post not found</h2>
                    <p style="color:var(--text-secondary);margin:1rem 0;">This post doesn't exist or the link is invalid.</p>
                    <a href="index.html#blog" class="back-btn" style="display:inline-flex;">
                        <i class="fas fa-arrow-left"></i> Back to Blog
                    </a>
                </div>`;
                return;
            }

            document.title = post.title + ' | Kamal Sharma';

            container.innerHTML = `
            <div style="max-width:820px;margin:0 auto;">
                <article class="blog-article">
                    <div class="post-meta-row">
                        <span class="post-tag">${post.tag}</span>
                        <span class="post-meta-item"><i class="fas fa-calendar-alt"></i> ${post.date}</span>
                        <span class="post-meta-item"><i class="fas fa-clock"></i> ${post.readTime}</span>
                    </div>
                    <div class="post-icon-hero"><i class="${post.icon}"></i></div>
                    <h1 class="post-title">${post.title}</h1>
                    <hr class="post-divider">
                    <div class="post-body">${post.body}</div>
                    <hr class="post-divider">
                    <div class="author-box">
                        <div class="author-avatar"><i class="fas fa-user"></i></div>
                        <div>
                            <div class="author-name">Kamal Sharma</div>
                            <div class="author-bio">Final-year ECE student | AI & Embedded Systems enthusiast</div>
                        </div>
                    </div>
                </article>
            </div>`;
        }

        // â”€â”€ Theme (same as main site) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        const savedTheme = localStorage.getItem('theme') || 'light';
        document.documentElement.setAttribute('data-theme', savedTheme);
        const themeBtn = document.getElementById('themeToggle');
        const updateThemeIcon = () => {
            const isDark = document.documentElement.getAttribute('data-theme') === 'dark';
            themeBtn.innerHTML = isDark ? '<i class="fas fa-sun"></i>' : '<i class="fas fa-moon"></i>';
        };
        updateThemeIcon();
        themeBtn.addEventListener('click', () => {
            const isDark = document.documentElement.getAttribute('data-theme') === 'dark';
            const next = isDark ? 'light' : 'dark';
            document.documentElement.setAttribute('data-theme', next);
            localStorage.setItem('theme', next);
            updateThemeIcon();
        });

        renderPost();
    </script>
</body>

</html>